{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn #neural network\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as TF\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Cuda Device and Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set test device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>data_set</th>\n",
       "      <th>condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 img  data_set  condition\n",
       "0  ..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...         0          0\n",
       "1  ..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...         0          0\n",
       "2  ..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...         0          0\n",
       "3  ..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...         0          0\n",
       "4  ..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...         0          0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_df = pd.read_csv(\"../../data/image_index.csv\", index_col=0)\n",
    "index_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = index_df[index_df.data_set==0]\n",
    "train_df = index_df[index_df.data_set==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = test_df.img[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Linear Prototype\n",
    "\n",
    "The issue with this model is that the output is `[1, 640, 2]` when the output should be a shape of `[2,]`. \n",
    "\n",
    "A flattening maybe required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_prototype(nn.Module):\n",
    "    def __init__(self, img_h, img_w):\n",
    "        super().__init__()\n",
    "        #define sizes here\n",
    "        self.h = img_h\n",
    "        self.w = img_w\n",
    "        self.linear1 = nn.Linear(img_w, 320)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(320, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # preprocess the input image\n",
    "        x = self.preprocess_image(x)\n",
    "        #============ Layer1==============#\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu1(x)\n",
    "        #============Layer2==============#\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        return self.softmax(x)\n",
    "    \n",
    "    ## update this to sequential?\n",
    "    def preprocess_image(self, path):\n",
    "        resizer = TF.Resize((self.h, self.w)) #define resizer per new_h and new_w\n",
    "        im = tv.io.read_image(path).type(torch.float) #read image as pytorch float tensor\n",
    "        im = resizer(im) #resize image\n",
    "        normalizer = TF.Normalize(im.mean(), im.std()) #initialize normalizer\n",
    "        return normalizer(im) # return normalized pytorch float tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "proto_model = linear_prototype(640, 640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "linear_prototype(\n",
       "  (linear1): Linear(in_features=640, out_features=320, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (linear2): Linear(in_features=320, out_features=2, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proto_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = proto_model(test_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 640, 2])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Linear Prototype with Flattened Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_prototype2(nn.Module):\n",
    "    def __init__(self, img_h, img_w):\n",
    "        super().__init__()\n",
    "        #define sizes here\n",
    "        self.h = img_h\n",
    "        self.w = img_w\n",
    "        self.longshape = img_h*img_w\n",
    "        self.linear1 = nn.Linear(self.longshape, 320)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(320, 2)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # preprocess the input image\n",
    "        x = self.preprocess_image_flat(x)\n",
    "        print(\"preprocess shape \", x.shape)\n",
    "        #============ Layer1==============#\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu1(x)\n",
    "        print(\"layer1 shape \", x.shape)\n",
    "        #============Layer2==============#\n",
    "        x = self.linear2(x)\n",
    "        print(\"layer2 shape \", x.shape)\n",
    "        return self.softmax(x)\n",
    "    \n",
    "    ## update this to sequential?\n",
    "    def preprocess_image_flat(self, path):\n",
    "        resizer = TF.Resize((self.h, self.w)) #define resizer per new_h and new_w\n",
    "        im = tv.io.read_image(path).type(torch.float) #read image as pytorch float tensor\n",
    "        im = resizer(im) #resize image\n",
    "        normalizer = TF.Normalize(im.mean(), im.std()) #initialize normalizer\n",
    "        im = normalizer(im) # return normalized pytorch float tensor\n",
    "        return torch.flatten(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = linear_prototype2(640, 640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess shape  torch.Size([409600])\n",
      "layer1 shape  torch.Size([320])\n",
      "layer2 shape  torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.4756, 0.5244], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin(test_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_loss(yhat, y):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fitsnbits",
   "language": "python",
   "name": "fitsnbits"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
