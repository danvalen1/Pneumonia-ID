{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn #neural network\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as TF\n",
    "import torch.optim as optim # optimizer\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Cuda Device and Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set test device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>data_set</th>\n",
       "      <th>condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 img  data_set  condition\n",
       "0  ..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...         0          0\n",
       "1  ..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...         0          0\n",
       "2  ..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...         0          0\n",
       "3  ..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...         0          0\n",
       "4  ..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...         0          0"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_df = pd.read_csv(\"../../data/image_index.csv\", index_col=0)\n",
    "index_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dummy = pd.get_dummies(index_df.condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dummy.columns = [\"negative\", \"positive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_df = pd.concat([index_df, result_dummy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>data_set</th>\n",
       "      <th>condition</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 img  data_set  condition  \\\n",
       "0  ..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...         0          0   \n",
       "1  ..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...         0          0   \n",
       "2  ..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...         0          0   \n",
       "3  ..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...         0          0   \n",
       "4  ..\\..\\data\\extracted\\chest_xray\\test\\NORMAL\\IM...         0          0   \n",
       "\n",
       "   negative  positive  \n",
       "0         1         0  \n",
       "1         1         0  \n",
       "2         1         0  \n",
       "3         1         0  \n",
       "4         1         0  "
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = index_df[index_df.data_set==0]\n",
    "train_df = index_df[index_df.data_set==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_df[[\"img\", \"negative\", \"positive\"]].sample(30, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = torch.tensor(train_data[[\"negative\", \"positive\"]].values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = train_data.img.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 2])"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "## update this to sequential?\n",
    "def preprocess_image_flat(path_list, img_h=640, img_w=640):\n",
    "    outlist = []\n",
    "    for path in path_list:\n",
    "        resizer = TF.Resize((img_h, img_w)) #define resizer per new_h and new_w\n",
    "        im = tv.io.read_image(path).type(torch.float) #read image as pytorch float tensor\n",
    "        im = resizer(im) #resize image\n",
    "        normalizer = TF.Normalize(im.mean(), im.std()) #initialize normalizer\n",
    "        im = normalizer(im) # return normalized pytorch float tensor\n",
    "        im = torch.flatten(im)\n",
    "        outlist.append(im)\n",
    "    return torch.stack(outlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = preprocess_image_flat(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 409600])"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Linear Prototype with Flattened Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_prototype2(nn.Module):\n",
    "    def __init__(self, img_h, img_w):\n",
    "        super().__init__()\n",
    "        #define sizes here\n",
    "        self.h = img_h\n",
    "        self.w = img_w\n",
    "        self.longshape = img_h*img_w\n",
    "        self.linear1 = nn.Linear(self.longshape, 320)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(320, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # preprocess the input image\n",
    "        x = self.preprocess_image_flat(x)\n",
    "        #============ Layer1==============#\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu1(x)\n",
    "        #============Layer2==============#\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "    ## update this to sequential?\n",
    "    def preprocess_image_flat(self, path):\n",
    "        resizer = TF.Resize((self.h, self.w)) #define resizer per new_h and new_w\n",
    "        im = tv.io.read_image(path).type(torch.float) #read image as pytorch float tensor\n",
    "        im = resizer(im) #resize image\n",
    "        normalizer = TF.Normalize(im.mean(), im.std()) #initialize normalizer\n",
    "        im = normalizer(im) # return normalized pytorch float tensor\n",
    "        im = torch.flatten(im)\n",
    "        return im.clone().detach().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_prototype3(nn.Module):\n",
    "    def __init__(self, img_h, img_w):\n",
    "        super().__init__()\n",
    "        #define sizes here\n",
    "        self.h = img_h\n",
    "        self.w = img_w\n",
    "        self.longshape = img_h*img_w\n",
    "        self.linear1 = nn.Linear(self.longshape, 320)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(320, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # preprocess the input image\n",
    "        #============ Layer1==============#\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu1(x)\n",
    "        #============Layer2==============#\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_prototype3(640, 640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 2])"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss(reduction=\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    y_true shape = observation, 2 (negative, positve)\n",
    "    y_pred shape = observation, 2 (negative, positive) but in posibilities\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    answers = list(zip(y_true, y_pred))\n",
    "    true_positives = sum(1 if (true[] == 1 and pred == 1) else 0 for true, pred in answers)\n",
    "    false_negatives = sum(1 if (true == 1 and pred == 0) else 0 for true, pred in answers)\n",
    "    return torch.tensor(1 - (true_positives/(true_positives + false_negatives)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optim(n_seq, learning_rate, img_paths):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for t in range(n_seq):\n",
    "        print(\"training epoch\", t)\n",
    "        y_pred = model(img_paths)\n",
    "        loss = criterion(y_pred, y_true) #calculate loss\n",
    "\n",
    "        plt.scatter(t, loss.detach())\n",
    "        optimizer.zero_grad() #reset gradient)\n",
    "        \n",
    "        # gradient back step\n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "        \n",
    "        # update parameters per learning rate (go down the gradient)\n",
    "        with torch.no_grad(): #sequential\n",
    "            for param in model.parameters():\n",
    "                param += learning_rate * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-585-7a25427951e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun_optim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-584-7b63de66c14e>\u001b[0m in \u001b[0;36mrun_optim\u001b[1;34m(n_seq, learning_rate, img_paths)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"training epoch\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#calculate loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-583-f45efa27d2a4>\u001b[0m in \u001b[0;36mf1_loss\u001b[1;34m(y_true, y_pred, is_training)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     '''\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_optim(10, 0.1, input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Linear Prototype\n",
    "\n",
    "The issue with this model is that the output is `[1, 640, 2]` when the output should be a shape of `[2,]`. \n",
    "\n",
    "A flattening maybe required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_prototype(nn.Module):\n",
    "    def __init__(self, img_h, img_w):\n",
    "        super().__init__()\n",
    "        #define sizes here\n",
    "        self.h = img_h\n",
    "        self.w = img_w\n",
    "        self.linear1 = nn.Linear(img_w, 320)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(320, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # preprocess the input image\n",
    "        x = self.preprocess_image(x)\n",
    "        #============ Layer1==============#\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu1(x)\n",
    "        #============Layer2==============#\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        return self.softmax(x)\n",
    "    \n",
    "    ## update this to sequential?\n",
    "    def preprocess_image(self, path):\n",
    "        resizer = TF.Resize((self.h, self.w)) #define resizer per new_h and new_w\n",
    "        im = tv.io.read_image(path).type(torch.float) #read image as pytorch float tensor\n",
    "        im = resizer(im) #resize image\n",
    "        normalizer = TF.Normalize(im.mean(), im.std()) #initialize normalizer\n",
    "        return normalizer(im) # return normalized pytorch float tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "proto_model = linear_prototype(640, 640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "linear_prototype(\n",
       "  (linear1): Linear(in_features=640, out_features=320, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (linear2): Linear(in_features=320, out_features=2, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proto_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = proto_model(test_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 640, 2])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optim2(n_seq, learning_rate, img_path_list):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for t in range(n_seq):\n",
    "        y_pred = [model(path) for path in img_path_list]\n",
    "        y_pred = torch.tensor([1 if pred[0] > pred[1] else 0 for pred in y_pred]).float()\n",
    "        y_pred = y_pred.clone().detach().requires_grad_(True)\n",
    "        \n",
    "        loss = criterion(y_pred, y_true) #calculate loss\n",
    "\n",
    "        plt.scatter(t, loss.detach())\n",
    "        optimizer.zero_grad() #reset gradient)\n",
    "        \n",
    "        # gradient back step\n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "        \n",
    "        # update parameters per learning rate (go down the gradient)\n",
    "        with torch.no_grad(): #sequential\n",
    "            for param in model.parameters():\n",
    "                if param.grad is not None:\n",
    "                    param += learning_rate * param.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fitsnbits",
   "language": "python",
   "name": "fitsnbits"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
